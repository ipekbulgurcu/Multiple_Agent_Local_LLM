# Local Multi-Agent RAG Service

**Yinov AI - Multi-Agent Assistant**, yerel LLM (Ollama) ve **LangGraph** kullanarak geliÅŸtirilmiÅŸ otonom bir yapay zeka sistemidir. Bu sistem, **Web Search**, **Python Code Execution** ve **Document RAG** yeteneklerini birleÅŸtirerek karmaÅŸÄ±k sorularÄ± Ã§Ã¶zer.

## ğŸš€ Proje HakkÄ±nda
Bu proje, sadece dokÃ¼man okuyan bir RAG sistemi deÄŸil, aynÄ± zamanda internete Ã§Ä±kabilen, kod yazabilen ve kararlar alabilen bir **Multi-Agent (Ã‡ok AjanlÄ±)** sistemdir. Verileriniz tamamen **yerel makinenizde** iÅŸlenir.

### ğŸŒŸ Ã–ne Ã‡Ä±kan Ã–zellikler
*   **Otonom Karar Verme (Router):** Supervisor (YÃ¶netici), sorunun tÃ¼rÃ¼ne gÃ¶re hangi ajanÄ± kullanacaÄŸÄ±na kendisi karar verir.
*   **Multi-Model Stratejisi (Task-Specific):**
    *   **HÄ±zlÄ± Model (Fast LLM):** YÃ¶nlendirme ve basit kararlar iÃ§in `phi3` veya `gemma` kullanÄ±r.
    *   **AkÄ±llÄ± Model (Smart LLM):** Kod yazma ve karmaÅŸÄ±k analizler iÃ§in `llama3` veya `mistral` kullanÄ±r.
*   **AraÃ§ KullanÄ±mÄ± (Tools):**
    *   DuckDuckGo Search (Ä°nternet AramasÄ±)
    *   Python REPL (Kod Ã‡alÄ±ÅŸtÄ±rma & Hesaplama)
    *   Vector Store (DokÃ¼man Analizi)
*   **LangGraph Orkestrasyonu:** DÃ¶ngÃ¼sel (Cyclic) grafik yapÄ±sÄ± sayesinde ajanlar birbirleriyle haberleÅŸerek sorunu Ã§Ã¶zene kadar Ã§alÄ±ÅŸÄ±r.

## ğŸ—ï¸ Mimari

Sistem, merkezi bir **Supervisor** node ve ona baÄŸlÄ± uzman ("Worker") node'lardan oluÅŸur:

1.  **Supervisor:** KullanÄ±cÄ± isteÄŸini analiz eder ve ilgili iÅŸÃ§iye yÃ¶nlendirir.
2.  **Researcher:** Ä°nternetten gÃ¼ncel bilgi toplar.
3.  **Coder:** Matematiksel iÅŸlemler ve veri analizi iÃ§in Python kodu yazar.
4.  **RAG Expert:** YÃ¼klenen dokÃ¼manlar Ã¼zerinde semantik arama yapar.

## ğŸ› ï¸ Kurulum AdÄ±mlarÄ±

Projeyi Ã§alÄ±ÅŸtÄ±rmak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlarÄ± takip edin.

### 1. Ã–n Gereksinimler
*   **Python 3.10+**: Sisteminizde Python yÃ¼klÃ¼ olmalÄ±dÄ±r.
*   **Ollama**: Yerel LLM servisi. [ollama.com](https://ollama.com) adresinden indirin.

### 2. Modelleri Ä°ndirin (Ã–nemli!)
Bu proje **iki farklÄ± model** kullanÄ±r. Terminalde ÅŸu komutlarÄ± Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
# Router iÃ§in hÄ±zlÄ± model
ollama pull phi3

# Ä°ÅŸlemler iÃ§in akÄ±llÄ± model
ollama pull llama3
```

*(Not: FarklÄ± modeller kullanmak isterseniz `app/core/config.py` dosyasÄ±nÄ± dÃ¼zenleyebilirsiniz.)*

### 3. Sanal Ortam Kurulumu
```bash
python -m venv venv
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate
```

### 4. BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin
```bash
pip install -r requirements.txt
```

### 5. UygulamanÄ± Ã‡alÄ±ÅŸtÄ±rÄ±n
Ollama servisinin arka planda Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun (`ollama serve`), ardÄ±ndan:

```bash
uvicorn app.main:app --reload
```
UygulamanÄ±z **http://127.0.0.1:8000** adresinde yayÄ±nda olacaktÄ±r.

---

## ğŸ§ª Testler

API'yi test etmek iÃ§in `/ask` endpoint'ine ÅŸu JSON ile POST isteÄŸi atabilirsiniz:

```json
{
  "query": "Who is the CEO of Apple and what is the current stock price?"
}
```
*Sistem Ã¶nce internetten CEO bilgisini bulacak, sonra borsa verisini Ã§ekecek ve birleÅŸtirip size sunacaktÄ±r.*

---
**GeliÅŸtirici:** Ä°pek Bulgurcu

